# RAG-Powered Multi-Agent Q&A Assistant

## Architecture Overview
This project is a smart Q&A assistant that uses a technique called Retrieval-Augmented Generation (RAG). It combines several tools like document search, text embedding, and language models to answer questions based on the information it has.

## Key Components:

1. Smart Document Search: Breaks documents into chunks and uses Sentence-BERT to turn them into searchable vectors stored with FAISS.

2. Query Handling: Detects keywords like “calculate” or “define” to use tools, or else searches for the best document chunks to answer your question.

3. Answer Generation: Uses the GPT-2 language model to write answers based on the most relevant content found.

4. User Interface: A simple Streamlit web app where users can ask questions and see results instantly..

## Key Design Choices:

1. FAISS for Fast Search: FAISS helps the system find the most relevant chunks quickly, even with a lot of data.

2. Sentence-BERT for Better Understanding: Instead of just matching keywords, Sentence-BERT helps the system understand the meaning behind questions and documents.

3. GPT-2 for Generating Answers: GPT-2 is used to generate human-like responses based on the context retrieved from the documents.

4. Organized Code: The project is split into multiple files like agent.py, vector_index.py, tools.py, and llm_utils.py to keep things clean and easy to manage.

## How to Run

### Prerequisites:
1. Python 3.x
2. Required Python packages (installed via `requirements.txt`): `faiss`, `sentence-transformers`, `transformers`, `requests`, `streamlit`, `dotenv`

### Installation:
1. Clone the repository
2. Install the dependencies
3. Set up environment variables

### Running the System
To run the web interface using Streamlit, execute: streamlit run app.py. This will launch the system in your web browser, where you can enter your queries and receive answers generated by the assistant.
